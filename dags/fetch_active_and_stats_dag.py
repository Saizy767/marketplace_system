from datetime import datetime
from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.empty import EmptyOperator
from airflow.exceptions import AirflowSkipException
from airflow.utils.task_group import TaskGroup
from src.operators.fetch_active_adverts import FetchActiveAdvertsOperator
from src.transformers.keyword_stats import KeywordStatsTransformer
from src.loaders.postgres_keyword_stats import PostgresKeywordStatsLoader
from src.db.postgres import PostgresEngineManager
from src.config.endpoints import get_endpoints
from src.api_client.generic import GenericApiClient
from src.schemas.api_schemas.stats_keywords import StatResponse

START_DATE = datetime(2025, 10, 1)

default_args = {
    "owner": "saizy",
    "retries": 3,
    "retry_delay": 60,
    "email_on_failure": False,
}

dag = DAG(
    dag_id="fetch_active_adverts_and_stats_combined",
    default_args=default_args,
    description="Fetch active adverts and collect stats in one DAG",
    schedule="@hourly",
    start_date=START_DATE,
    catchup=False,
    tags=["api", "etl", "adverts", "keywords", "dynamic"],
)

# 1. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ñ
fetch_active_task = FetchActiveAdvertsOperator(
    task_id="fetch_active_adverts",
    dag=dag,
)

# 2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ñ
def check_active_adverts(**context):
    ti = context["task_instance"]
    active_ids = ti.xcom_pull(task_ids="fetch_active_adverts")
    
    if not active_ids or not isinstance(active_ids, list) or len(active_ids) == 0:
        return "no_active_adverts"
    return "prepare_advert_ids"

check_adverts_task = BranchPythonOperator(
    task_id="check_active_adverts",
    python_callable=check_active_adverts,
    dag=dag,
)

no_active_adverts_task = EmptyOperator(task_id="no_active_adverts", dag=dag)
end_task = EmptyOperator(task_id="end", dag=dag, trigger_rule="none_failed")

# 3. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ID Ğ´Ğ»Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
def prepare_advert_ids(**context):
    ti = context["task_instance"]
    active_ids = ti.xcom_pull(task_ids="fetch_active_adverts")
    
    if not active_ids:
        raise AirflowSkipException("No active adverts found")
    
    context["task_instance"].log.info(f"Preparing {len(active_ids)} active adverts for processing: {active_ids}")
    
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑĞ»Ğ¾Ğ²Ğ°Ñ€ĞµĞ¹ Ğ´Ğ»Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
    return [{"advert_id": str(aid)} for aid in active_ids]

prepare_advert_ids_task = PythonOperator(
    task_id="prepare_advert_ids",
    python_callable=prepare_advert_ids,
    dag=dag,
)

# 4. ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ETL Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ advert_id
def execute_full_etl(advert_id, **context):
    """
    Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ETL Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ advert_id Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
    """
    ti = context["task_instance"]
    ti.log.info(f"ğŸš€ Starting FULL ETL process for advert_id: {advert_id}")
    
    try:
        # === 1. Extract ===
        ti.log.info(f"ğŸ” Fetching keywords data for advert_id: {advert_id}")
        params = {
            "id": str(advert_id).strip(),
            "from": context["data_interval_start"].strftime("%Y-%m-%d"),
            "to": context["data_interval_end"].strftime("%Y-%m-%d"),
        }
        ti.log.info(f"FOUND DATA:\n{params}")
        
        client = GenericApiClient(timeout=30)
        raw_data = client.fetch_data(
            url=get_endpoints().STATISTIC_WORDS,
            params=params,
            response_model=StatResponse,
        )
        ti.log.info(f"âœ… Successfully fetched data for advert_id: {advert_id}, found {len(raw_data.stat)} records")

        # === 2. Transform ===
        ti.log.info(f"ğŸ”„ Transforming data for advert_id: {advert_id}")
        transformer = KeywordStatsTransformer()
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµÑ‚ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€
        dag_run_conf = {"advert_id": advert_id}
        task_context = {
            **context,
            "dag_run": type('obj', (object,), {'conf': dag_run_conf})
        }
        
        transformed_data = transformer.transform(raw_data, **task_context)
        ti.log.info(f"âœ… Successfully transformed {len(transformed_data)} records for advert_id: {advert_id}")
        
        # === 3. Load ===
        ti.log.info(f"ğŸ’¾ Loading data to database for advert_id: {advert_id}")
        engine_manager = PostgresEngineManager(conn_id="postgres")
        loader = PostgresKeywordStatsLoader(engine_manager=engine_manager)
        
        loaded_count = loader.load(transformed_data)
        ti.log.info(f"âœ… Successfully loaded {loaded_count} records for advert_id: {advert_id} into keyword_stats table")
        
        return {
            "advert_id": advert_id,
            "records_loaded": loaded_count,
            "status": "success"
        }
        
    except Exception as e:
        ti.log.error(f"âŒ ETL process FAILED for advert_id {advert_id}: {str(e)}")
        raise

# 5. Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ ETL Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ advert_id
etl_tasks = PythonOperator.partial(
    task_id="execute_etl_for_advert",
    python_callable=execute_full_etl,
    dag=dag,
).expand(op_kwargs=prepare_advert_ids_task.output)

# Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸
fetch_active_task >> check_adverts_task
check_adverts_task >> [no_active_adverts_task, prepare_advert_ids_task]
no_active_adverts_task >> end_task
prepare_advert_ids_task >> etl_tasks >> end_task